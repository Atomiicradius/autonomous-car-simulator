# 5-Minute Demo Script

## Setup (Before Demo)

**Pre-demo checklist:**
- [ ] Backend server running (`python backend_server.py`)
- [ ] Frontend open in browser (`http://localhost:5000` or `frontend/index.html`)
- [ ] Test simulation works (quick 10-second test)
- [ ] Have comparison results ready (run `python run_test_matrix.py` beforehand if time permits)
- [ ] Close unnecessary applications
- [ ] Set browser zoom to 100%

---

## Demo Flow (5 Minutes)

### 0:00-0:45 - Introduction (Person 1 or Team Lead)

**Script:**
> "Good [morning/afternoon]. We've built an **ALU-based autonomous vehicle simulator** that demonstrates custom decision logic for self-driving cars. Our system uses a **5-state finite state machine** running on a 100ms control loop, just like a real IoT microcontroller would."

**Show:** Architecture diagram (from ARCHITECTURE.md or draw on whiteboard)

**Key points:**
- 4 proximity sensors â†’ ALU decision engine â†’ motion commands
- Real-time simulation with quantitative performance analysis
- 3 driving modes showing safety vs efficiency tradeoff

---

### 0:45-1:30 - ALU Explanation (Person 2 - ALU Engineer)

**Script:**
> "The heart of our system is the ALU decision engine. It implements a **5-state FSM**: CRUISE, AVOID_LEFT, AVOID_RIGHT, EMERGENCY_BRAKE, and REVERSING. We have **3 driving modes**â€”Cautious, Normal, and Aggressiveâ€”that use the same ALU architecture but different safety thresholds."

**Show:** State diagram (from README.md or ARCHITECTURE.md)

**Key points:**
- Hazard score computation: normalized danger value 0.0-1.0
- Time-To-Collision (TTC) prediction for proactive braking
- Hysteresis mechanism prevents state oscillation

**Demo tip:** Keep this brief, focus on the "WOW" features (TTC prediction)

---

### 1:30-3:30 - Live Demo (Person 3 operates, Person 4 narrates)

**Person 3:** Control the dashboard  
**Person 4:** Narrate what's happening

#### Part 1: Normal Mode (45 seconds)

**Actions:**
1. Select "Normal" mode
2. Select "Random" scenario
3. Click "Start"

**Person 4 narrates:**
> "Here's our simulation running in real-time. The **blue rectangle** is the car, **red circles** are obstacles, and **green lines** are the sensor rays. Watch the metrics panel on the rightâ€”you can see the **FSM state**, **speed**, **hazard score**, and **time-to-collision** updating every 100ms."

**Point out:**
- Car successfully avoiding obstacles
- State changing from CRUISE to AVOID_LEFT/RIGHT
- Hazard bar fluctuating (green â†’ yellow â†’ red)
- Sensor values updating in real-time

#### Part 2: Mode Comparison (45 seconds)

**Actions:**
1. Pause simulation
2. Switch to "Aggressive" mode
3. Click "Start"

**Person 4 narrates:**
> "Now watch what happens in **Aggressive mode**. The car goes much faster, gets closer to obstacles, and you'll see more collisions. Notice the hazard score spikes higher and more frequently."

**Let run for 20-30 seconds**

**Actions:**
1. Pause simulation
2. Switch to "Cautious" mode  
3. Click "Start"

**Person 4 narrates:**
> "In **Cautious mode**, the car is much more conservative. It maintains larger safety margins, the hazard score stays lower, and collisions are rare. But notice the speed is also lowerâ€”this demonstrates the **safety vs efficiency tradeoff**."

**Let run for 15-20 seconds**

#### Part 3: WOW Features (30 seconds)

**Person 4 narrates:**
> "Our system includes two advanced features. First, **sensor noise and filtering**â€”we can inject Gaussian noise and apply a moving average filter for stable readings. Second, **predictive collision avoidance** using Time-To-Collision estimation. When TTC drops below a threshold, the ALU triggers emergency braking *before* the obstacle is critically close."

**Actions:**
- Point to TTC value on screen
- Mention noise/filter toggles (even if not actively demonstrating)

---

### 3:30-4:30 - Results & Analysis (Person 1 or Person 3)

**Show:** Results table (from test matrix or prepared screenshot)

**Script:**
> "We tested **4 scenarios** across **3 modes**â€”that's 12 configurations total. Here are the results:"

**Show table:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Scenario     â”‚ Mode       â”‚ Collisions â”‚ Avg Speed   â”‚ Avg Hazard   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Random       â”‚ Cautious   â”‚ 0          â”‚ 1.8 m/s     â”‚ 0.18         â”‚
â”‚ Random       â”‚ Normal     â”‚ 1          â”‚ 2.2 m/s     â”‚ 0.25         â”‚
â”‚ Random       â”‚ Aggressive â”‚ 4          â”‚ 2.8 m/s     â”‚ 0.42         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key points:**
- Cautious: 0 collisions, slowest speed, lowest hazard
- Aggressive: Most collisions, fastest speed, highest hazard
- **Clear quantitative proof** of safety-speed tradeoff

**Show:** Hazard vs time chart (if available)

**Script:**
> "This chart shows hazard score over time. You can see Cautious mode stays in the safe zone, while Aggressive frequently spikes into danger."

---

### 4:30-5:00 - Conclusion & Q&A Setup (Person 2 or Team Lead)

**Script:**
> "To summarize: we've built a **complete ALU-based IoT control system** with realistic sensors, custom decision logic, real-time operation, and **quantitative validation**. This demonstrates core digital logic conceptsâ€”combinational logic for decisions, sequential logic for state management, and a clocked control loop."

**Transition to Q&A:**
> "The logic we've implemented can be directly ported to hardware like Arduino or STM32 for a real robot car. We're ready for questions."

---

## Backup Plan (If Live Demo Fails)

**Have ready:**
1. **Screenshots** of the dashboard in action
2. **Pre-recorded video** (optional, record 30-second clip beforehand)
3. **Results table** printed or on slides

**Script if demo fails:**
> "We're experiencing a technical issue with the live demo, but let me show you screenshots of the system in action..."

---

## Viva Q&A Preparation

### Expected Questions & Answers

**Q: How does this relate to digital logic design?**

**A:** "Our ALU is a **combinational logic block**: sensor inputs go through comparisons and threshold checks to produce outputs. The state machine is **sequential logic** with a state register updated every clock cycle. The 100ms loop is our clock period, just like hardware."

---

**Q: Why three different modes?**

**A:** "To prove the same ALU architecture can exhibit different behaviors through **configuration only**, like how FPGAs and microcontrollers use programmable parameters. This is more flexible than hardcoding behavior."

---

**Q: What was the hardest part?**

**A:** "Preventing **state oscillation**. The car would rapidly flip between AVOID_LEFT and AVOID_RIGHT when sensors fluctuated. We solved this with **hysteresis**â€”a state must hold for multiple cycles before transitioning. This is a real-world digital logic technique."

---

**Q: How is this IoT-related?**

**A:** "This is exactly the **sense-decide-act loop** an IoT microcontroller executes: read ADC from sensors, run decision logic, output PWM to motors. We're simulating it safely before deploying to hardware. The code structure directly maps to embedded C."

---

**Q: Can you add more features?**

**A:** "Yes, several possibilities:
- Machine learning to auto-tune thresholds
- Multi-vehicle coordination (V2V communication)
- Camera-based prediction
- Hardware deployment with ROS/Gazebo
- Path planning algorithms"

---

**Q: How did you validate correctness?**

**A:** "We wrote **comprehensive unit tests** for each moduleâ€”physics, sensors, ALU logic. We ran **scenario tests** across all configurations. We collected **quantitative metrics** (collisions, speed, hazard) and verified they match expected behavior. All tests pass with 100% success rate."

---

**Q: What if sensors fail?**

**A:** "We handle edge cases: if a sensor returns max range (no obstacle), we treat it as safe. If it returns zero (stuck), we can detect the anomaly. We also tested with **sensor noise** to ensure the filter stabilizes readings. In production, we'd add redundancy and fault detection."

---

## Presentation Roles

**Assign before demo:**

| Role | Person | Responsibility |
|------|--------|----------------|
| Intro | Person 1 | Project overview, architecture |
| ALU Explanation | Person 2 | FSM, states, thresholds |
| Demo Operator | Person 3 | Control dashboard, switch modes |
| Demo Narrator | Person 4 | Explain what's happening on screen |
| Results | Person 1 | Show data, charts, conclusions |
| Q&A Lead | Person 2 | Field technical questions |

**Everyone:** Be ready to answer questions about your specific contribution.

---

## Final Checklist

**30 minutes before:**
- [ ] Test full demo flow once
- [ ] Verify all team members know their parts
- [ ] Have backup materials ready
- [ ] Close unnecessary browser tabs
- [ ] Set phone to silent

**5 minutes before:**
- [ ] Backend server running
- [ ] Frontend loaded and connected
- [ ] Reset simulation to clean state
- [ ] Deep breath, you got this! ðŸš€

---

## Time Management

If running over time:
- **Skip:** Detailed ALU explanation (keep to 30 seconds)
- **Skip:** Noise/filter demo (just mention it exists)
- **Keep:** Live demo of mode differences (most impressive)
- **Keep:** Results table (proves quantitative validation)

If running under time:
- **Add:** Show CSV data in Excel
- **Add:** Demonstrate mode comparison API call
- **Add:** Show state diagram in more detail

---

**Good luck! You've built something impressive. Show it with confidence!** ðŸ’ª
